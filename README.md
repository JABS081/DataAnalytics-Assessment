# DataAnalyticsâ€‘Assessment

This repository contains **fullyâ€‘documented solutions** to the SQL Proficiency Assessment. Each script solves a realistic business question, while this README provides deepâ€‘dive explanations, query logic, formula breakdowns, sample outputs, useâ€‘case context, and troubleshooting notesâ€”demonstrating complete SQL proficiency.

> **Prepared byâ€¯:** **JABS** Â |Â  **Dateâ€¯:** 17â€¯Mayâ€¯2025 Â |Â  **Timeâ€¯Zoneâ€¯:** Africa/Lagos

---

## ğŸ“š TableÂ ofÂ Contents

* [Repository Structure](#repository-structure)
* [General Assumptions](#general-assumptions)
* [Perâ€‘Question ExplanationsÂ &Â SampleÂ Outputs](#perâ€‘question-explanations--sample-outputs)

  * [1Â â€“Â Highâ€‘Value Customers with Multiple Products](#1-highâ€‘value-customers-with-multiple-products)
  * [2Â â€“Â Transaction Frequency Analysis](#2-transaction-frequency-analysis)
  * [3Â â€“Â Account Inactivity Alert](#3-account-inactivity-alert)
  * [4Â â€“Â Customer Lifetime Value (CLV) Estimation](#4-customer-lifetime-value-clv-estimation)
* [ChallengesÂ &Â Resolutions](#challenges--resolutions)
* [AdditionalÂ Notes](#additional-notes)
* [ContributingÂ &Â Feedback](#contributing--feedback)

---

## Repository Structure

| File                                       | Question                                    |
| ------------------------------------------ | ------------------------------------------- |
| [`Assessment_Q1.sql`](./Assessment_Q1.sql) | Highâ€‘Value CustomersÂ withÂ MultipleÂ Products |
| [`Assessment_Q2.sql`](./Assessment_Q2.sql) | TransactionÂ FrequencyÂ Analysis              |
| [`Assessment_Q3.sql`](./Assessment_Q3.sql) | AccountÂ InactivityÂ Alert                    |
| [`Assessment_Q4.sql`](./Assessment_Q4.sql) | CustomerÂ LifetimeÂ ValueÂ (CLV)Â Estimation    |

---

## General Assumptions

1. **Currency** â€” All monetary fields are stored in **kobo** (â‚¦â€¯Ã—â€¯100). Queries divide byÂ 100 to present values in **naira**.
2. **Timestamps** â€” Columns such as `created_at` (transactions) and `date_joined` (users) are available for date arithmetic.
3. **Active Accounts** â€” Every account returned is assumed active unless explicitly filtered out.
4. **Plan Flags**
   â€¢ `is_regular_savingsÂ =Â 1`Â â†’ savings plans
   â€¢ `is_a_fundÂ =Â 1`Â â†’ investment plans
5. **Data Hygiene** â€” Queries coalesce `NULL`s and format numbers for consistent, humanâ€‘readable output.

---

## Perâ€‘Question ExplanationsÂ &Â SampleÂ Outputs

### 1Â â€“Â Highâ€‘Value Customers with Multiple Products

**Objective**â€¯: list customers who hold **both** a funded savings plan **and** a funded investment plan, ranked by total deposits.

**Query Highlights**

* Join `users_customuser`, `savings_savingsaccount`, and `plans_plan`.
* Filter rows where `is_regular_savingsÂ =Â 1` **and** `is_a_fundÂ =Â 1`.
* Aggregate per customer with `GROUPÂ BY owner_id`.
* Compute:
  `COUNT(DISTINCT savings_id)` **and** `COUNT(DISTINCT investment_id)`
  `SUM(confirmed_amount)/100`Â â†’ `total_deposits` (â‚¦).
* `HAVING` ensures at least one of each product; sorted `DESC` by deposits.

```sql
-- key formula
SUM(savings.confirmed_amount) / 100 AS total_deposits
```

| owner\_id | name     | savings\_count | investment\_count | total\_deposits |
| --------: | -------- | -------------: | ----------------: | --------------: |
|      1001 | JohnÂ Doe |              2 |                 1 |       15â€¯000.00 |
|      1003 | JaneÂ Ali |              3 |                 2 |       13â€¯250.50 |

---

### 2Â â€“Â Transaction Frequency Analysis

**Objective**â€¯: segment customers by **average monthly transaction count**.

**Logic**

1. `DATE_TRUNC('month', created_at)`Â â†’ month bucket.
2. Count monthly tx per customer: `COUNT(*)`.
3. Average those counts: `AVG(tx_count)`.
4. Categorize via `CASE`.

```sql
CASE
  WHEN avg_tx_per_month >= 10 THEN 'High Frequency'
  WHEN avg_tx_per_month BETWEEN 3 AND 9 THEN 'Medium Frequency'
  ELSE 'Low Frequency'
END AS frequency_category
```

| frequency\_category | customer\_count | avg\_transactions\_per\_month |
| ------------------- | --------------: | ----------------------------: |
| HighÂ Frequency      |             250 |                          15.2 |
| MediumÂ Frequency    |           1â€¯200 |                           5.5 |
| LowÂ Frequency       |             600 |                           1.9 |

---

### 3Â â€“Â Account Inactivity Alert

**Objective**â€¯: surface active accounts (savingsÂ or investment) with **no inflow in the lastÂ 365Â days**.

```sql
CURRENT_DATE - MAX(created_at) AS inactivity_days
```

| plan\_id | owner\_id | type       | last\_transaction\_date | inactivity\_days |
| -------: | --------: | ---------- | ----------------------- | ---------------: |
|     1001 |       305 | Savings    | 2023â€‘08â€‘10              |              400 |
|     1010 |       450 | Investment | 2023â€‘01â€‘12              |              480 |

---

### 4Â â€“Â Customer Lifetime Value (CLV) Estimation

**Objective**â€¯: estimate **CLV** using tenure and a profit rate of **0.1â€¯%** per transaction.

```sql
(total_transactions / tenure_months) * 12 * avg_profit_per_transaction AS estimated_clv
```

| customer\_id | name     | tenure\_months | total\_transactions | estimated\_clv |
| -----------: | -------- | -------------: | ------------------: | -------------: |
|         1001 | JohnÂ Doe |             24 |                 120 |         600.00 |
|         1002 | GraceÂ O. |             36 |                  90 |         300.00 |

---

## ChallengesÂ &Â Resolutions

| Challenge                                                    | Resolution                                                                                                                |
| ------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------- |
| *Incomplete Schema* â€” column names/types not fully specified | Assumed conventional fields (`created_at`, `confirmed_amount`, `date_joined`) and explained assumptions in code comments. |
| *Currency in Kobo* â€” risk of misreporting                    | Standardised all value outputs by dividing byÂ 100 and documenting the conversion.                                         |
| *Frequency Edge Cases*                                       | Used inclusive CASE ranges to avoid offâ€‘byâ€‘one misclassification.                                                         |
| *Plan Type Ambiguity*                                        | Utilised explicit boolean flags `is_regular_savings`, `is_a_fund` to separate savings vs. investment.                     |
| *Overlapping Inactivity*                                     | Combined savings & investment via `UNION ALL`, tagging each row with a `type` field.                                      |

---

## Additional Notes

* Queries follow ANSIâ€‘SQL; minor tweaks adapt them to PostgreSQL/MySQL/SQLite.
* Each `.sql` file is selfâ€‘contained, idempotent, and heavily commented.
* Output formats align with stakeholder reporting needs.
* NULL handling, date arithmetic, and currency precision are explicitly managed.

---

## ContributingÂ &Â Feedback

Have an idea, spotted an issue, or want to share feedback? **Open an Issue or pull request!**

1. Click the **Issues** tab or [start a new issue](https://github.com/Jabs081/DataAnalytics-Assessment/issues/new) and describe your suggestion or problem.
2. Fork the repo, commit your fixes to a feature branch, and open a **PullÂ Request**â€”weâ€™ll review ASAP.

> *MaintainerÂ username*: **[@Jabs081](https://github.com/Jabs081)**

---

**PreparedÂ &Â submitted by**Â |Â **JABS**
**Date**Â |Â 17Â MayÂ 2025
**Location**Â |Â Africa/Lagos
